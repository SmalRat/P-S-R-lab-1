---
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Lera Fedorchak, Oleksandra Maslenchenko, Oleksandr Shchur*

## Introduction

During the past three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;\
see [this
site](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)
for more detailed explanations.

## Data description

There are 5 datasets uploaded on the cms.

To determine your variant, take your team number from the list of teams
on cms and take *mod 5* - this is the number of your data set.

-   **0 - authors** This data set consists of citations of three famous
    writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP
    Lovecraft. The task with this data set is to classify a piece of
    text with the author who was more likely to write it.

-   **1 - discrimination** This data set consists of tweets that have
    discriminatory (sexism or racism) messages or of tweets that are of
    neutral mood. The task is to determine whether a given tweet has
    discriminatory mood or does not.

-   **2 - fake news** This data set contains data of American news: a
    headline and an abstract of the article. Each piece of news is
    classified as fake or credible. The task is to classify the news
    from test.csv as credible or fake.

-   **3 - sentiment** All the text messages contained in this data set
    are labeled with three sentiments: positive, neutral or negative.
    The task is to classify some text message as the one of positive
    mood, negative or neutral.

-   **4 - spam** This last data set contains SMS messages classified as
    spam or non-spam (ham in the data set). The task is to determine
    whether a given message is spam or non-spam.

Each data set consists of two files: *train.csv* and *test.csv*. The
first one you will need find the probabilities distributions for each of
the features, while the second one is needed for checking how well your
classifier works.


## Instructions

-   The first step is data pre-processing, which includes removing
    punctuation marks and stop words

-   represent each message as a bag-of-words

-   using the training set, calculate all the conditional probabilities
    in formula (1)

-   use those to predict classes for messages in the test set

-   evaluate effectiveness of the classifier by calculating the
    corresponding metrics

-   shortly summarize your work

-   do not forget to submit both the (compiled) Rmd source file and the .html
    output
    
### Data pre-processing

-   Read the *.csv* data files.
-   Ð¡lear your data from punctuation or other unneeded symbols.
-   Clear you data from stop words. You don't want words as is, and, or
    etc. to affect your probabilities distributions, so it is a wise
    decision to get rid of them. Find list of stop words in the cms
    under the lab task.
-   Represent each test message as its bag-of-words. Here:
    <https://machinelearningmastery.com/gentle-introduction-bag-words-model/>
    you can find general introduction to the bag-of-words model and
    examples on to create it.
-   It is highly recommended to get familiar with R dataframes, it would
    make the work much easier to do.
-   Useful links:
    -   <https://steviep42.github.io/webscraping/book/bagofwords.html#tidytext> -
        example of using *tidytext* to count frequencies of the words.
    -   Basics of Text Mining in R:
        <http://rstudio-pubs-static.s3.amazonaws.com/256588_57b585da6c054349825cba46685d8464.html>
        . Note that it also includes an example on how to create a bag
        of words from your text document.




```{r}
# here goes a list of recommended libraries,
# though you may install other ones if they are needed
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
library(tm)

list.files(getwd())
list.files("data/1-discrimination")

test_path <- "data/1-discrimination/test.csv"
train_path <- "data/1-discrimination/train.csv"

stop_words <- read_file("stop_words.txt")
Word_stop_words <- strsplit(stop_words, split='\n')[[1]]

train <-  read.csv(file = train_path, stringsAsFactors = FALSE)
test <-  read.csv(file = test_path, stringsAsFactors = FALSE)


create_new_bag_of_words_with_label <- function(path, flag){
  stop_words <- read_file("stop_words.txt")
  Word_stop_words <- strsplit(stop_words, split='\n')[[1]]
  file_text <- read.csv(file = path, stringsAsFactors = FALSE)
  tidy_t <- unnest_tokens(file_text, 'Word', 'tweet', token="words") %>%
             filter(!(Word %in% Word_stop_words) & (nchar(Word) > 2))
  posts_text <- filter(tidy_t, label == flag)
  posts_counted <- count(posts_text, Word, sort=TRUE)
  return (posts_counted)
}

create_bag_of_words <- function(path) {
  stop_words <- read_file("stop_words.txt")
  Word_stop_words <- strsplit(stop_words, split='\n')
  Word_stop_words <- Word_stop_words[[1]]
  file_text <- read.csv(file = path, stringsAsFactors = FALSE)
  tidy_t <- unnest_tokens(file_text, 'Word', 'tweet', token="words") %>%
             filter(!(Word %in% Word_stop_words) & (nchar(Word) > 2))
  return (tidy_t)
}

create_labeled_dataframe <- function(tidy_t, flag) {
  posts_text <- filter(tidy_t, label == flag)
  posts_counted <- count(posts_text, Word, sort=TRUE)
  return (posts_counted)
}


tidy_t <- create_bag_of_words("data/1-discrimination/train.csv")
neutral_posts_counted <- create_labeled_dataframe(tidy_t, "neutral")
discrimination_posts_counted <- create_labeled_dataframe(tidy_t, "discrim")

```


### Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!

Neutral posts statistics:

```{r}
head(neutral_posts_counted, 20) %>%
  mutate(Word = reorder(Word, n)) %>%
  ggplot(aes(Word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()



```
Discrimination posts statistics:

```{r}
head(discrimination_posts_counted, 20) %>%
  mutate(Word = reorder(Word, n)) %>%
  ggplot(aes(Word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

```

## Classifier implementation

```{r}
naiveBayes <- setRefClass("naiveBayes",
                          
       # here it would be wise to have some vars to store intermediate result
       # frequency dict etc. Though pay attention to bag of wards! 
       fields = list(data = "data.frame", labels = "vector", labels_quantity = "numeric", unique_words = "numeric", labels_probabilities = "numeric"),
       methods = list(
                    # prepare your training data as X - bag of words for each of your
                    # messages and corresponding label for the message encoded as 0 or 1 
                    # (binary classification task)
                    fit = function(X, y)
                    {
                         labels_probabilities <<- vector("numeric", length(unlist(labels)))
                         unique_words <<- length(unique(X$Word))
                         count_frame = count(train, label, sort=TRUE)
                         n_total = sum(count_frame$n)
                         for (label in seq(1,length(unlist(labels)))){
                           labels_probabilities[label] <<- (count_frame[count_frame$label == labels[label], "n"])/n_total
                         }
                         #print(labels_probabilities)
                         for (i in seq(1,length(unlist(labels)))){
                           current_label <- unlist(labels)[i]
                           
                           column_name = paste("P(word|",current_label,")")
                           
                           current_topic = filter(X, label == current_label) %>% count(Word, sort=TRUE)
                           
                           current_topic[column_name] = (current_topic["n"]+1)/(sum(current_topic$n) + unique_words)
                           
                           colnames(current_topic)[2] <- paste("n_", current_label)
                          
                           data <<- merge(data, current_topic, by = "Word", all = TRUE)
                           
                         }
                         data <<- data[order(data[1], decreasing = TRUE), ]
                         
                         for (label in seq(1,length(unlist(labels)))){
                           current_label <- unlist(labels)[label]
                           column_name = paste("P(word|",current_label,")")
                           data[column_name][is.na(data[column_name])] <<- 1/(sum(data[paste("n_", labels[label])], na.rm=TRUE) + unique_words)
                         }
                         
                         #print(data)
                         
                        
                         
                         
                         
                    },
                    
                    # return prediction for a single message 
                    predict = function(message)
                    {
                         purified <- tolower(message) %>% removePunctuation() %>% removeNumbers() %>% stripWhitespace()
                         words <- strsplit(purified, " +")[[1]]
                         words <- setdiff(words, Word_stop_words)
                         words_probability_vector = vector(mode="numeric", length=length(words)*length(labels))
                         relevant_data = data[data$Word %in% words, ]
                         
                         for (word in words){
                           if (!(word %in% data$Word)){
                             probability_vector = vector(mode="numeric", length=ncol(data)-1)
                             for (label in seq(1,length(unlist(labels)))){
                               non_zero_probability = 1/(sum(data[paste("n_", labels[label])], na.rm=TRUE) + unique_words)
                               probability_vector[2*label-1] = 0
                               probability_vector[2*label] = non_zero_probability
                             
                             }
                             relevant_data[nrow(relevant_data)+1,] <- c(c(word), probability_vector)
                           }
                         }
                         #print(relevant_data)
                         
                         
                         for (label in seq(1,length(labels))){
                          column_name = paste("P(word|", labels[label], ")")
                          for (word in seq(1,length(words))){
                            probability <- relevant_data[relevant_data$Word==words[word],][column_name]
                            words_probability_vector[(label-1)*length(words) + word] = probability
                            }
                         }
                         multiplication_product_vector = vector("numeric",length(labels)*2)
                         words_probability_vector <- as.numeric(unlist(words_probability_vector))
                         for (label in seq(1,length(labels))){
                           product = 1
                           multiplication = 0
                           for (word in seq(1,length(words))){
                             product = product * words_probability_vector[(label-1)*length(words) + word]
                             while (product < 1){
                               multiplication = multiplication + 1
                               product = product * 10
                             }
                           }
                           product = product * labels_probabilities[label]
                           multiplication_product_vector[2*label] = product
                           multiplication_product_vector[2*label-1] = multiplication
                           
                         }
                         multiplication_vector = vector("numeric",length(labels))
                         product_vector = vector("numeric",length(labels))
                         
                         for (label in seq(1,length(labels))){
                           multiplication_vector[label] = multiplication_product_vector[2*label-1]
                           product_vector[label] = multiplication_product_vector[2*label]
                         }
                         
                         #print(product_vector)
                         #print(multiplication_vector)
                         current_max = multiplication_vector[1];
                         idxs <- c()
                         range <- 1:length(multiplication_vector)
                         for (i in range) {
                           if (!(is.na(multiplication_vector[i])) && (multiplication_vector[i] > current_max)) {
                             current_max = multiplication_vector[i]
                           }
                         }
                         for (i in range) {
                           if (!(is.na(multiplication_vector[i])) && (multiplication_vector[i] == current_max)) {
                             idxs <- append(idxs, i)
                           } 
                         }
                         #print(idxs)
                         max = idxs[1]
                         if (length(idxs) > 1){
                           max = -1
                           for (idx in idxs) {
                             if (product_vector[idx] > max) {
                               max = idx
                             }
                            }
                           }
                         #print(max)
                         #print(labels)
                        
                         return(labels[max])
                    },
                    
                    # score you test set so to get the understanding how well you model
                    # works.
                    # look at f1 score or precision and recall
                    # visualize them 
                    # try how well your model generalizes to real world data! 
                    score = function(filepath)
                    {
                      
                      test <-  head(read.csv(file = filepath, stringsAsFactors = FALSE), 100)
                      predictions = vector(length=nrow(test))
                      
                      
                      count = 1
                      
                      for (message in test$tweet) {
                        prediction <- model$predict(message)
                        # predictions[count] = predict(message)
                        if (prediction == 1) {
                          
                          predictions[count] <- "discrim"
                        } else {
                          predictions[count] <-"neutral" 
                        }
                        count = count + 1
                      }
                      # print(predictions)
                      #print(test)
                      
                      # data1 <- data1[, -1]
                      #print(predictions)
                      true_labels = test[ ,"label"]
                      #print(true_labels)

                      counter = 0
                      for (i in 1:length(true_labels)) {
                      
                        if (predictions[i] == true_labels[i]) {
                          counter = counter + 1
                        }
                      }
                      #print(counter)
                      #print(length(true_labels))
                      total <- length(true_labels)
                      slices <- c((total-counter), counter)
                      lbls <- c("wrong predictions", "correct predictions")
                      pie(slices, labels = lbls, main="statistics of corectness")
                    }
       ))
                    

words_list = list(unique(tidy_t$Word))
model = naiveBayes(labels=unique(tidy_t$label), data=data.frame("Word" = unlist(words_list)), labels_quantity=length(unique(tidy_t$label)))
model$fit(X=tidy_t)
#print(model$predict("Trump black wertafyyfay the in a zzzzzzzz"))
model$score(test_path)
```

## Measure effectiveness of your classifier
-   Note that accuracy is not always a good metric for your classifier.
    Look at precision and recall curves, F1 score metric.
-   Visualize them.
-   Show failure cases.

## Conclusions

Summarize your work by explaining in a few sentences the points listed
below.

-   Describe the method implemented in general. Show what are
    mathematical foundations you are basing your solution on.
-   List pros and cons of the method. This should include the
    limitations of your method, all the assumption you make about the
    nature of your data etc.
